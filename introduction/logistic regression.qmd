---
title: harmonic mean
jupyter: python3
---

```{python}
import sklearn
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import preprocessing
from sklearn.metrics import (confusion_matrix,
                             precision_score,
                             recall_score,
                             f1_score,
                             classification_report,
                             precision_recall_curve,
                             roc_curve,
                             roc_auc_score)

from matplotlib import pyplot as plt
```

```{python}
mnist = datasets.fetch_openml('mnist_784', version = 1)
```

```{python}
type(mnist)
```

```{python}
mnist.keys()
```

```{python}
mnist_data = mnist['data'].values
```

```{python}
mnist_data.shape
```

```{python}
28 * 28
```

```{python}
mnist_data[12345].reshape(28, 28)
```

```{python}
plt.imshow(mnist_data[12345].reshape(28, 28), cmap = plt.cm.binary, interpolation = 'nearest');
```

```{python}
plt.imshow(mnist_data[57].reshape(28, 28), cmap = plt.cm.binary, interpolation = 'nearest');
```

```{python}
mnist_data[57]
```

```{python}
fig = plt.figure(figsize = (15, 15))

for i in range(100):
    fig.add_subplot(10, 10, i + 1, xticks = [], yticks = [])
    plt.imshow(mnist_data[i].reshape(28, 28), cmap = plt.cm.binary, interpolation = 'nearest');
```

```{python}
mnist.keys()
```

```{python}
mnist['target']
```

```{python}
type(mnist['target'])
```

```{python}
mnist_target = mnist['target'].values
```

```{python}
mnist_target
```

```{python}
s = train_test_split(mnist_data, mnist_target)
```

```{python}
len(s)
```

```{python}
X_train, X_test, y_train, y_test = train_test_split(mnist_data, 
                                                    mnist_target,
                                                    test_size=0.2,
                                                    random_state=101)
```

```{python}
X_train.shape
```

```{python}
X_test.shape
```

```{python}
y_train.shape
```

```{python}
y_test.shape
```

```{python}
y_train
```

```{python}
y_train = y_train == '8'
```

```{python}
y_train
```

```{python}
y_test = y_test == '8'
```

```{python}
y_train.mean(), y_test.mean()
```

```{python}
y_train
```

```{python}
logreg = LogisticRegression(max_iter = 10000)
```

```{python}
X_train = preprocessing.scale(X_train)
```

```{python}
X_test = preprocessing.scale(X_test)
```

```{python}
X_train
```

```{python}
fig = plt.figure(figsize = (15, 15))

for i in range(100):
    fig.add_subplot(10, 10, i + 1, xticks = [], yticks = [])
    plt.imshow(X_train[i].reshape(28, 28), cmap = plt.cm.binary, interpolation = 'nearest');
```

```{python}
preprocessing.scale
```

```{python}
X_train.var()
```

```{python}
result = logreg.fit(X_train, y_train)
```

```{python}
result
```

```{python}
X_train
```

```{python}
y_train
```

```{python}
result.predict(X_train)
```

```{python}
result.predict_proba(X_train)
```

```{python}
prob = result.predict_proba(X_train)[:,1]
```

```{python}
%rep 95
```

```{python}
fig = plt.figure(figsize = (15, 15))

for i in range(100):
    fig.add_subplot(10, 10, i + 1, xticks = [], yticks = [])
    plt.imshow(X_train[i].reshape(28, 28), cmap = plt.cm.binary, interpolation = 'nearest');
    plt.title(prob[i].round(3))
```

```{python}
logreg.predict(X_train)
```

```{python}
logreg.predict_proba(X_train)[:,1] > 0.5
```

```{python}
(logreg.predict(X_train) == (logreg.predict_proba(X_train)[:,1] > 0.5)).mean()
```

```{python}
y_test
```

```{python}
y_test_classification = logreg.predict(X_test)
```

```{python}
confusion_matrix(y_test, y_test_classification)
```

```{python}
y_test.sum()
```

```{python}
y_test_classification.sum()
```

```{python}
y_test_classification.shape
```

```{python}
168 + 958
```

```{python}
 391 +958
```

```{python}
precision_score(y_test, y_test_classification)
```

```{python}
958 / (958 + 168)
```

```{python}
recall_score(y_test, y_test_classification)
```

```{python}
958 / (391 +  958)
```


Reciprocal of the arithmetic mean of the reciprocals of the precision and recall scores.


```{python}
f1_score(y_test, y_test_classification)
```

```{python}
precision = precision_score(y_test, y_test_classification)
recall = recall_score(y_test, y_test_classification)
```

```{python}
1/((1/precision + 1/recall)/2)
```

```{python}
print(classification_report(y_test, y_test_classification))
```

```{python}
p = logreg.predict_proba(X_test)[:,1]
```

```{python}
import numpy as np
```

```{python}
logodds = np.log(p) - np.log(1 - p)
```

```{python}
precisions, recalls, thresholds = precision_recall_curve(y_test, logodds)
```

```{python}
precisions.shape
```

```{python}
recalls.shape
```

```{python}
thresholds.shape
```

```{python}
plt.plot(thresholds, precisions[:-1], 'r.')
plt.plot(thresholds, recalls[:-1], 'b.')
```

```{python}
fpr, tpr, thresholds = roc_curve(y_test, logodds)
```

```{python}
plt.plot(fpr, tpr, 'b.')
plt.plot([0, 1], [0, 1])
plt.xlabel("False positive rate")
plt.ylabel("True positive rate")
```

```{python}
roc_auc_score(y_test, logodds)
```


